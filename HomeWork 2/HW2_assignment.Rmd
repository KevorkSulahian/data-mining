---
title: "Homework 2"
author: ""
date: ""
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=F, message=F)
```

## we will be using housing dataset and you are also provided with the  the description of that data set

(2 point)Load the data housing.csv and check whether the data types are correct, if not, make appropriate corrections assigning labels to each level according to the data description, so that it will be easy to interprete the model results during the next steps.

Pay attention to the variable grade. You can use function cut() here os something like it.

```{r}
house <- read.csv("housing.csv")
str(house)
house$date <- sub("T000000", "", house$date)
house$date <- as.numeric(house$date)
#house <- transform(house, date = as.Date(as.character(date), "%Y%m%d"))
```

(2 points) Create a variable with building's age (The data is collected at 2018). visualize the relationship between the newly created variable with the price and comment whether it can be significant predictor for the price.

```{r}
house$age = 2018 - house$yr_built
library(ggplot2)
options(scipen=10000)
ggplot(house, aes(x = age, y = price)) + geom_point()
# As it seems in the graph the age doesn't have any major effect on the price
```

(2 points) Our goal in this analysis will be building a model to preddict the price of houses as accurately as possible. First, write a code to check what variables are highly correlated with the price variable.
Hint: use function ?cor()

```{r}
sapply(house, is.numeric)
cor(house)
```

(3 points) Visualize the relationship between the independent variables. In case you see it might cause multicolinearity  during the modeling, also print correlation coeficients and make a note to act accordingly during modeling.
Hint: usually variables having more than 0.7 correlation coeficients might cause multicolinearity.

1. the relationship between numbeer of bedrooms and living area in sqft

```{r}
attach(house)
cor(bedrooms, sqft_living) # 0.57
ggplot(house, aes(x = bedrooms,y = sqft_living)) + geom_point() +
  xlim(c(1,10))
```
2. the relationship betweeen the living area in sqft and the number of bathrooms
```{r}
cor(sqft_living, bathrooms) # .75 => multicolinearity 
ggplot(house, aes(x = sqft_living, y = bathrooms)) + geom_point()
```
3. the relationship between number of bedrooms and number of bathrooms
```{r}
cor(bathrooms, bedrooms) # .51
ggplot(house, aes(x = bedrooms, y = bathrooms)) + geom_point() +
  xlim(c(1,10))
```

4. the relationship betwen sqft_living and sqft_above 
```{r}
cor(sqft_living,sqft_above) # .87 => multicolinearity
ggplot(house, aes(x = sqft_living, y = sqft_above)) + geom_point()

```

(5 point) Usig ggplot visualizations explore the relationships between categorical variables and price.
Also try to visualize whether the relationship between price and other numeric variables differ based on categorical variables such as waterfront, view, condition and grade.
```{r}
# waterfront, view, condition, grade
#house$waterfront <- as.factor(house$waterfront)
ggplot(house, aes(x = waterfront , y = price))+ geom_point()
ggplot(house, aes(x = view , y = price))+ geom_point()
ggplot(house, aes(x = condition , y = price))+ geom_point()
ggplot(house, aes(x = grade , y = price))+ geom_point()
```

(1 point) divide the dataframe into Train and Test including in the Train dataset 80% of the observations and 20%, respectively, in Test dataset.
```{r}
sample <- sample(nrow(house), floor(nrow(house) * .8))
train <- house[sample,]
test <- house[-sample,]
```

(4 points) Build an inittial model on Training dataset including as predictors all possible variables and comment on the model performance based on R square and R square Adjusted (which one will you use in this case).
```{r}
model1 <- lm(price ~ date + bedrooms +bathrooms + sqft_living +
               sqft_lot + floors+ waterfront + view + condition +
               grade + sqft_above + yr_built + yr_renovated +zipcode +
               lat + long + sqft_living15 + sqft_lot15, data = train)
summary(model1) # r = .702, r^2 = .7016
# R and R^2 are close and higher than the 50% which means that our model is good
```

(5 points) What variables are signifcant predictors in the model?
Comment on the relationships between each independent variable with the dependent variable. (Be attentive in determining the reference group while interpreting the relatipnships in case of categorical variable)

```{R}
# Date: this simply means that every day the price of houses are increasing from the intercept
# Bedrooms, bathrooms increasing or decreasing them changes based on the intercept
# sqft_living, sqft_lot (insignificant), floors (insignificant) more of these = higher price
# waterfront true => higher price, view & condition & grade higher points => higher price
# sqft_above same as other sqrft
# yr_built, yr_renovated changes the price basedon built and if renovated
# zipcode, lat, long changes the price based on location
# sqft_living15 sqft_lot15  price changes based on how big their neighbhoors houses are
```

(4 points) Remove the variables you consider might cause multicolinearity, explain the logic how you decide to omit this or that variable from the correlated pairs. Comment on the changes of model performance based on R square and coefficients.

```{r}

```

(3 points) Try changing the reference group for grade variable to be high,(use the function ?relevel)
run and save the 3rd model. Comment on the changes of coefficients, their significance and the overall model performance. 
```{r}
library(olsrr)
ols_coll_diag(model1)
```


(3 points) Make predictions on the testing data set using all 3 models, calculate RMSE and comment what model is doing better
```{r}

```

